{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd396232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from models.decoder import Decoder\n",
    "from models.encoder import Encoder\n",
    "from utils.dataset_C111 import SpinodoidC111Dataset\n",
    "from utils.dataset_C212 import SpinodoidC212Dataset\n",
    "from utils.sampling import get_S_hats, get_S_hat_peaks\n",
    "from utils.fNN_layers import *\n",
    "from utils.load_data import extract_target_properties, full_C_from_C_flat_21\n",
    "from config import *\n",
    "\n",
    "# === settings ===\n",
    "SEED = 42\n",
    "COMPONENT_NAME = \"C111\"  # or \"C212\"\n",
    "COMPONENT_INDEX = 0 if COMPONENT_NAME == \"C111\" else 6\n",
    "\n",
    "# === set seed ===\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === choose trial ===\n",
    "trial = 1\n",
    "trial_dir = f\"checkpoints/{COMPONENT_NAME}_{trial}\"\n",
    "decoder_path = f\"{trial_dir}/decoder_ckpt_{trial}.pt\"\n",
    "encoder_path = f\"{trial_dir}/encoder_ckpt_{trial}.pt\"\n",
    "config_path  = f\"{trial_dir}/config_{trial}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === load config ===\n",
    "with open(config_path) as f:\n",
    "    config = {line.split(\":\")[0].strip(): eval(line.split(\":\")[1].strip()) for line in f}\n",
    "LATENT_DIM = config[\"LATENT_DIM\"]\n",
    "S_DIM = config[\"S_DIM\"]\n",
    "P_DIM = config[\"P_DIM\"]\n",
    "ENCODER_HIDDEN_DIMS = config[\"ENCODER_HIDDEN_DIMS\"]\n",
    "DECODER_HIDDEN_DIMS = config[\"DECODER_HIDDEN_DIMS\"]\n",
    "\n",
    "# === load dataset ===\n",
    "dataset = SpinodoidC111Dataset(DATA_PATH) if COMPONENT_NAME == \"C111\" else SpinodoidC212Dataset(DATA_PATH)\n",
    "P_all, S_all = dataset.P, dataset.S\n",
    "P_target = P_all[0].unsqueeze(0).to(device)\n",
    "S_true = S_all[0].detach().cpu().numpy()\n",
    "\n",
    "# === load models ===\n",
    "encoder = Encoder(S_DIM, P_DIM, LATENT_DIM, ENCODER_HIDDEN_DIMS).to(device)\n",
    "encoder.load_state_dict(torch.load(encoder_path, map_location=device))\n",
    "encoder.eval()\n",
    "\n",
    "decoder = Decoder(S_DIM, P_DIM, LATENT_DIM, DECODER_HIDDEN_DIMS).to(device)\n",
    "decoder.load_state_dict(torch.load(decoder_path, map_location=device))\n",
    "decoder.eval()\n",
    "\n",
    "print(\"✅ Models loaded for trial\", trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === load Max’s fNN model ===\n",
    "custom_objects = {\n",
    "    'PermutationEquivariantLayer': PermutationEquivariantLayer,\n",
    "    'DoubleContractionLayer': DoubleContractionLayer,\n",
    "    'EnforceIsotropyLayer': EnforceIsotropyLayer,\n",
    "    'NormalizationLayer': NormalizationLayer\n",
    "}\n",
    "fNN = tf.keras.models.load_model('utils/max_fNN.h5', custom_objects=custom_objects)\n",
    "print(\"✅ Loaded Max's forward model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e385a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === sample Ŝ from decoder and extract peaks ===\n",
    "S_hats = get_S_hats(decoder, P_target, LATENT_DIM, num_samples=1000, device=device)\n",
    "S_hat_peaks = get_S_hat_peaks(S_hats, bandwidth=0.5)\n",
    "print(f\"✅ Sampled {len(S_hat_peaks)} peaks\")\n",
    "\n",
    "# === evaluate peak predictions using fNN ===\n",
    "S_hat_peaks_tensor = torch.tensor(S_hat_peaks, dtype=torch.float32)\n",
    "P_preds_all = []\n",
    "\n",
    "for s_hat in S_hat_peaks_tensor:\n",
    "    s_hat_np = s_hat.unsqueeze(0).numpy()  # shape: (1, 4)\n",
    "    C_flat_pred = fNN.predict(s_hat_np, verbose=0)  # shape: (1, 21)\n",
    "    C_tensor_pred = full_C_from_C_flat_21(C_flat_pred)\n",
    "    P_pred_vec = extract_target_properties(C_tensor_pred)[0]\n",
    "    P_pred_scalar = P_pred_vec[COMPONENT_INDEX].item()\n",
    "    P_preds_all.append(P_pred_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ec6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === compare with true P ===\n",
    "P_true_scalar = P_target.cpu().numpy().flatten()[0]\n",
    "mse = mean_squared_error([P_true_scalar] * len(P_preds_all), P_preds_all)\n",
    "\n",
    "print(f\"\\n✅ MSE across {len(P_preds_all)} peak predictions:\")\n",
    "print(f\"   - True {COMPONENT_NAME} value: {P_true_scalar:.5f}\")\n",
    "print(f\"   - Predicted {COMPONENT_NAME} values: {np.round(P_preds_all, 5)}\")\n",
    "print(f\"   - MSE: {mse:.6f}\")\n",
    "\n",
    "# === plot prediction bar chart ===\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(np.arange(len(P_preds_all)), P_preds_all, color='skyblue')\n",
    "plt.axhline(P_true_scalar, color='red', linestyle='--', label='True value')\n",
    "plt.xlabel(\"Peak index\")\n",
    "plt.ylabel(f\"Predicted {COMPONENT_NAME}\")\n",
    "plt.title(f\"{COMPONENT_NAME} Predictions from Ŝ Peaks (Trial {trial})\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
